{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base-line\n",
    "\n",
    "This the baseline of the project.\n",
    "\n",
    "A Random Forest model is implemented, which loads a dataset and applies StandardScaler transformation to all numerical fields, also applies 70-30 partition for train and test sets respectively, achieving a final accuracy around 85%, and cross validation accuracy around 82%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scope\n",
    "\n",
    "The expected scope of this project is implementation of techniques and good practices to achieve deployment of the full functionality of this code through REST API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Situation\n",
    "\n",
    "This is an excersice taken from kaggle to work with, in which the objective is to try to determine the median value of owner-occupied homes in $1000's [k\\$] (**MEDV**, dependent variable), given a serie of independent variables like structural, neighborhood, accessibility and air pollution data in Boston around 70's.\n",
    "\n",
    "To know more about the dataset you can see directly kaggle [link](https://www.kaggle.com/datasets/fedesoriano/the-boston-houseprice-data)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook\n",
    "\n",
    "The following code in this notebook was tacken from several notebooks developed by other users in kaggle platform.\n",
    "\n",
    "* [MAGANTI IT](https://www.kaggle.com/code/magantiit/linearregression)\n",
    "* [SADIK AL JARIF](https://www.kaggle.com/code/sadikaljarif/boston-housing-price-prediction) \n",
    "* [MARCIN RUTECKI](https://www.kaggle.com/code/marcinrutecki/regression-models-evaluation-metrics)\n",
    "* [UNMOVED](https://www.kaggle.com/code/unmoved/regress-boston-house-prices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Section to place all imports required to execute code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "import opendatasets as od\n",
    "import os\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants\n",
    "Section to place all CONSTANTS needed to execute code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_DIR = './datasets/'\n",
    "KAGGLE_URL = \"https://www.kaggle.com/datasets/fedesoriano/the-boston-houseprice-data\" \n",
    "KAGGLE_LOCAL_DIR = KAGGLE_URL.split('/')[-1]\n",
    "DATA_RETRIEVED = 'data.csv'\n",
    "\n",
    "COLUMNS = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT','MEDV']\n",
    "TARGET = 'MEDV'\n",
    "FEATURES = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "NUMERICAL_FEATURES = ['CRIM', 'ZN', 'INDUS', 'NOX', 'RM', 'AGE', 'DIS', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "CATEGORICAL_FEATURES = ['CHAS','RAD']\n",
    "SELECTED_FEATURES = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT']\n",
    "\n",
    "YEO_JOHNSON_FEATURES = ['B']\n",
    "\n",
    "SEED_SPLIT = 42\n",
    "SEED_MODEL = 102\n",
    "\n",
    "TRAINED_MODEL_DIR = 'trained_models/'\n",
    "PIPELINE_NAME = 'random_forest'\n",
    "PIPELINE_SAVE_FILE = f'{PIPELINE_NAME}_output.pkl'\n",
    "\n",
    "#VARIABLES\n",
    "droped_rows_index_list = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "\n",
    "Section to write down all functions to implement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_data():\n",
    "\n",
    "    #Downloads dataset from kaggle with pre-defined structure (folder)\n",
    "    od.download(KAGGLE_URL, force=True)\n",
    "\n",
    "    #Finds the recently downloaded file\n",
    "    paths = sorted(Path(KAGGLE_LOCAL_DIR).iterdir(), key=os.path.getmtime)\n",
    "    path_new_file = str(paths[-1])\n",
    "    name_new_file = str(path_new_file).split('\\\\')[-1]\n",
    "\n",
    "    #If recently downloaded file already exists in root, delete it\n",
    "    if os.path.isfile(path_new_file):\n",
    "        print(\"Dataset downloaded: \" + path_new_file)\n",
    "    else:\n",
    "        print(\"Something went wrong, dataset not downloades!\")\n",
    "\n",
    "    #Moves the file to root instead of downloaded folder\n",
    "    if os.path.isfile(DATASETS_DIR + name_new_file):        #Searches for the new file downloaded\n",
    "        os.remove(DATASETS_DIR + name_new_file)             #   and deletes it\n",
    "    if os.path.isfile(DATASETS_DIR + DATA_RETRIEVED):       #Searches for any old file with FILE_NAME specified\n",
    "        os.remove(DATASETS_DIR + DATA_RETRIEVED)            #   and deletes it too\n",
    "    os.rename(path_new_file, DATASETS_DIR + DATA_RETRIEVED) #Finally, moves downloaded file to default datasets folder\n",
    "    print(\"And stored in: \" + DATASETS_DIR + DATA_RETRIEVED)\n",
    "    shutil.rmtree(KAGGLE_LOCAL_DIR)                         #Deletes the folder where kaggle library downloaded dataset\n",
    "\n",
    "\n",
    "\n",
    "#retrieve_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Reg_Models_Evaluation_Metrics (model,X_train,y_train,X_test,y_test,y_pred):\n",
    "    cv_score = cross_val_score(estimator = model, X = X_train, y = y_train, cv = 10)\n",
    "    \n",
    "    # Calculating Adjusted R-squared\n",
    "    r2 = model.score(X_test, y_test)\n",
    "    # Number of observations is the shape along axis 0\n",
    "    n = X_test.shape[0]\n",
    "    # Number of features (predictors, p) is the shape along axis 1\n",
    "    p = X_test.shape[1]\n",
    "    # Adjusted R-squared formula\n",
    "    adjusted_r2 = 1-(1-r2)*(n-1)/(n-p-1)\n",
    "    RMSE = np.sqrt(metrics.mean_squared_error(y_test, y_pred))\n",
    "    R2 = model.score(X_test, y_test)\n",
    "    CV_R2 = cv_score.mean()\n",
    "\n",
    "    return [[R2, adjusted_r2, CV_R2, RMSE]]\n",
    "    \n",
    "    #print('R2:', round(R2,4))\n",
    "    #print('Adjusted R2:', round(adjusted_r2, 4) )\n",
    "    #print(\"Cross Validated R2: \", round(cv_score.mean(),4) )\n",
    "    #print('RMSE:', round(RMSE,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(df):\n",
    "    #Obtains features that will be an input for the model\n",
    "    #Extracts features from final dataframe, excluding TARGET and CATEGORICAL_FEATURES that were transformed to OHE\n",
    "\n",
    "    df = df.drop(CATEGORICAL_FEATURES).copy()\n",
    "    df = df.drop(TARGET).copy()\n",
    "    return df.columns\n",
    "\n",
    "#get_features(df_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def persist_model():\n",
    "    #Saves the model recently trained\n",
    "    \n",
    "    if not os.path.isdir(TRAINED_MODEL_DIR):   #Searches for the default models folder\n",
    "        os.mkdir(Path(TRAINED_MODEL_DIR))\n",
    "    if os.path.isdir(TRAINED_MODEL_DIR):\n",
    "        joblib.dump(RF_model, TRAINED_MODEL_DIR + PIPELINE_SAVE_FILE)\n",
    "\n",
    "    print(\"Model stored in: \" + TRAINED_MODEL_DIR + PIPELINE_SAVE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invsere_standard_scaler(value):\n",
    "    # Returns a standard scaled value to its original value.\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(value)\n",
    "    value = scaler.inverse_transform(value)\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Transformers\n",
    "\n",
    "Section to allocate all custom transformers to implement in the pipeline.\n",
    "\n",
    "It is importan to define them as classes insted of functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MissingIndicator(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom scikit-learn transformer to create indicator features for missing values in specified variables.\n",
    "\n",
    "    Parameters:\n",
    "        variables (list or str, optional): List of column names (variables) to create indicator features for.\n",
    "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
    "\n",
    "    Attributes:\n",
    "        variables (list): List of column names (variables) to create indicator features for.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            This method does not perform any actual training or fitting.\n",
    "            It returns the transformer instance itself.\n",
    "\n",
    "        transform(X):\n",
    "            Creates indicator features for missing values in the specified variables and returns the modified DataFrame.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Instantiate the custom transformer\n",
    "    missing_indicator = MissingIndicator(variables=['age', 'income'])\n",
    "\n",
    "    # Define the pipeline with the custom transformer\n",
    "    pipeline = Pipeline([\n",
    "        ('missing_indicator', missing_indicator),\n",
    "        # Other pipeline steps...\n",
    "    ])\n",
    "\n",
    "    # Fit and transform the data using the pipeline\n",
    "    X_transformed = pipeline.fit_transform(X)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, variables=None):\n",
    "        \"\"\"\n",
    "        Initialize the MissingIndicator transformer.\n",
    "\n",
    "        Parameters:\n",
    "            variables (list or str, optional): List of column names (variables) to create indicator features for.\n",
    "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
    "        \"\"\"\n",
    "        if not isinstance(variables, list):\n",
    "            self.variables = [variables]\n",
    "        else:\n",
    "            self.variables = variables\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        This method does not perform any actual training or fitting, as indicator features are created based on data.\n",
    "        It returns the transformer instance itself.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input data to be transformed. Not used in this method.\n",
    "            y (pd.Series or np.array, optional): Target variable. Not used in this method.\n",
    "\n",
    "        Returns:\n",
    "            self (MissingIndicator): The transformer instance.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Creates indicator features for missing values in the specified variables and returns the modified DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input data to be transformed.\n",
    "\n",
    "        Returns:\n",
    "            X_transformed (pd.DataFrame): Transformed DataFrame with additional indicator features for missing values.\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "        for var in self.variables:\n",
    "            X[f'{var}_nan'] = X[var].isnull().astype(int)*1\n",
    "\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IQR_DropOutliers (BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom scikit-learn transformer that takes a dataframe and list of features to return the same dataframe modified excluding outliers according to the Tukey IQR method.\n",
    "\n",
    "    Parameters:\n",
    "        n (int): Number of outliers permited on features.\n",
    "        features (list of string): List of numeric features on which to obtain outliers.\n",
    "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
    "\n",
    "    Attributes:\n",
    "        features (list): List of features on which to obtain outliers.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            This method does not perform any actual training or fitting.\n",
    "            It returns the transformer instance itself.\n",
    "\n",
    "        transform(X):\n",
    "            Finds outliers\n",
    "            Creates indicator features for missing values in the specified variables and returns the modified DataFrame.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Instantiate the custom transformer\n",
    "    iqr_dropoutliers = IQR_DropOutliers(n=1, features=['sales', 'transactions'])\n",
    "\n",
    "    # Define the pipeline with the custom transformer\n",
    "    pipeline = Pipeline([\n",
    "        ('iqr_dropoutliers', iqr_dropoutliers),\n",
    "        # Other pipeline steps...\n",
    "    ])\n",
    "\n",
    "    # Fit and transform the data using the pipeline\n",
    "    X_transformed = pipeline.fit_transform(X)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, features=None, n=0):\n",
    "        \"\"\"\n",
    "        Initialize the IQR_DropOutliers transformer.\n",
    "\n",
    "        Parameters:\n",
    "            features (list of string): List of numeric features on which to obtain outliers.\n",
    "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
    "        \"\"\"\n",
    "        if not isinstance(features, list):\n",
    "            self.features = [features]\n",
    "        else:\n",
    "            self.features = features\n",
    "\n",
    "        self.n = n\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        This method does not perform any actual training or fitting.\n",
    "        It returns the transformer instance itself.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input data to be transformed. Not used in this method.\n",
    "\n",
    "        Returns:\n",
    "            self (IQR_DropOutliers): The transformer instance.\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Identifies outliers in the list of features to drop them from input dataframe and returns the modified dataframe.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input data to be transformed.\n",
    "\n",
    "        Returns:\n",
    "            X_transformed (pd.DataFrame): Transformed DataFrame without outliers.\n",
    "        \"\"\"\n",
    "\n",
    "        outliers_index_list = []\n",
    "        for feature in self.features:\n",
    "            Q1 = np.percentile(X[feature], 25)     # 1st quartile (25%)\n",
    "            Q3 = np.percentile(X[feature],75)      # 3rd quartile (75%)\n",
    "            IQR = Q3 - Q1                           # Interquartile range (IQR)\n",
    "            outlier_step = 1.5 * IQR                # Outlier step for the current feature\n",
    "            outlier_index_list = X[(X[feature] < Q1 - outlier_step) | (X[feature] > Q3 + outlier_step )].index   # Determining a list of indices of outliers\n",
    "            outliers_index_list.extend(outlier_index_list)                                                          # appending the list of outliers \n",
    "            \n",
    "        # Selecting observations containing more than n outliers\n",
    "        outlier_index_counts = Counter(outliers_index_list)        \n",
    "        outlieres_list = list( k for k, v in outlier_index_counts.items() if v > self.n )\n",
    "\n",
    "        # Droping outliers found\n",
    "        X = X.drop(outlieres_list, axis = 0).reset_index(drop=True)\n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DropMissing (BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom scikit-learn transformer that takes missing indicator variables to drop records and drop \"_na\" variables later.\n",
    "\n",
    "    Parameters:\n",
    "        This transformer does not need parameters.\n",
    "\n",
    "    Attributes:\n",
    "        This transformer does not need attributes.\n",
    "\n",
    "    Methods:\n",
    "        fit(X):\n",
    "            This method does not perform any actual training or fitting.\n",
    "            It returns the transformer instance itself.\n",
    "\n",
    "        transform(X):\n",
    "            Drop NA records, and drop NA missing indicator variables later.\n",
    "            Returns the modified DataFrame.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Instantiate the custom transformer\n",
    "    dropna = DropMissing()\n",
    "\n",
    "    # Define the pipeline with the custom transformer\n",
    "    pipeline = Pipeline([\n",
    "        ('dropna', DropMissing),\n",
    "        # Other pipeline steps...\n",
    "    ])\n",
    "\n",
    "    # Fit and transform the data using the pipeline\n",
    "    X_transformed = pipeline.fit_transform(X)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize the DropMissing transformer.\n",
    "\n",
    "        Parameters:\n",
    "            This transformer does not need parameters. \n",
    "        \"\"\"\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        This method does not perform any actual training or fitting.\n",
    "        It returns the transformer instance itself.\n",
    "\n",
    "        Parameters:\n",
    "            This transformer does not need parameters.\n",
    "\n",
    "        Returns:\n",
    "            self (DropMissing): The transformer instance.\n",
    "        \"\"\"\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Based on missing values indicators identifies records with NA values to drop them from input dataframe and returns the modified dataframe.\n",
    "\n",
    "        Parameters:\n",
    "            This transformer does not need parameters.\n",
    "\n",
    "        Returns:\n",
    "            X_transformed (pd.DataFrame): Transformed DataFrame without missing values records and whitout missing indicator variables.\n",
    "        \"\"\"\n",
    "\n",
    "        nans_index_list = []\n",
    "        nan_columns = [col for col in X.columns if 'nan' in col]\n",
    "\n",
    "        for column in nan_columns:\n",
    "            nan_index_list = X[X[column] == 1].index   # Determining a list of indices of outliers\n",
    "            nans_index_list.extend(nan_index_list)                                                          # appending the list of outliers \n",
    "            \n",
    "        # Selecting observations containing missing values\n",
    "        nan_index_counts = Counter(nans_index_list)        \n",
    "        self.nans_list = list( k for k, v in nan_index_counts.items() if v > 0 )\n",
    "        print(self.nans_list)\n",
    "\n",
    "        # Droping records with missing found\n",
    "        X = X.drop(self.nans_list, axis = 0).reset_index(drop=True)\n",
    "        X = X.drop(nan_columns, axis = 1)               # Drops columns with postfix 'nan'\n",
    "        \n",
    "        return X\n",
    "\n",
    "\n",
    "#aux = raw_df.copy()\n",
    "#nandroped = DropMissing()\n",
    "#nandroped.fit(aux)\n",
    "#AUX = nandroped.transform(aux)\n",
    "#AUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom scikit-learn transformer to perform one-hot encoding for categorical features.\n",
    "\n",
    "    Parameters:\n",
    "        features (list or str, optional): List of column names (features) to perform one-hot encoding for.\n",
    "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
    "\n",
    "    Attributes:\n",
    "        features (list): List of column names (features) to perform one-hot encoding for.\n",
    "        dummies (list): List of column names representing the one-hot encoded dummy features.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            Calculates the one-hot encoded dummy feature columns for the specified categorical features.\n",
    "            It returns the transformer instance itself.\n",
    "\n",
    "        transform(X):\n",
    "            Performs one-hot encoding for the specified categorical features and returns the modified DataFrame.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Instantiate the custom transformer\n",
    "    ohe_encoder = OneHotEncoder(variables=['category1', 'category2'])\n",
    "\n",
    "    # Define the pipeline with the custom transformer\n",
    "    pipeline = Pipeline([\n",
    "        ('ohe_encoder', ohe_encoder),\n",
    "        # Other pipeline steps...\n",
    "    ])\n",
    "\n",
    "    # Fit and transform the data using the pipeline\n",
    "    X_transformed = pipeline.fit_transform(X)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, features=None):\n",
    "        \"\"\"\n",
    "        Initialize the OneHotEncoder transformer.\n",
    "\n",
    "        Parameters:\n",
    "            features (list or str, optional): List of column names (features) to perform one-hot encoding for.\n",
    "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
    "        \"\"\"\n",
    "        self.features = [features] if not isinstance(features, list) else features\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        Calculates the one-hot encoded dummy variable columns for the specified categorical features.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input data to be transformed.\n",
    "\n",
    "        Returns:\n",
    "            self (OneHotEncoder): The transformer instance.\n",
    "        \"\"\"\n",
    "        self.dummies = pd.get_dummies(X[self.features], drop_first=False).columns\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Performs one-hot encoding for the specified categorical features and returns the modified DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input data to be transformed.\n",
    "\n",
    "        Returns:\n",
    "            X_transformed (pd.DataFrame): Transformed DataFrame with one-hot encoded dummy variables for the specified categorical features.\n",
    "        \"\"\"\n",
    "        X = X.copy()\n",
    "        X = pd.concat([X, pd.get_dummies(X[self.features], drop_first=False)], axis=1)\n",
    "        X.drop(self.features, axis=1)\n",
    "\n",
    "        # Adding missing dummies, if any\n",
    "        #missing_dummies = [var for var in self.dummies if var not in X.columns]\n",
    "        #if len(missing_dummies) != 0:\n",
    "        #    for col in missing_dummies:\n",
    "        #        X[col] = 0\n",
    "\n",
    "        return X\n",
    "    \n",
    "    \n",
    "#print(CATEGORICAL_FEATURES)\n",
    "#aux = raw_df.copy()\n",
    "#aux['CHAS'] = aux['CHAS'].astype(str)\n",
    "#aux['RAD'] = aux['RAD'].astype(str)\n",
    "#one_encoder = OneHotEncoder(features=['RAD'])\n",
    "#one_encoder.fit(aux)\n",
    "#AUX = one_encoder.transform(aux)\n",
    "#AUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Standard_Scaler(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Custom scikit-learn transformer to perform standard scaling on features except target feature.\n",
    "\n",
    "    Parameters:\n",
    "        features (list or str): List of column names (features) to perform StandardScaler.\n",
    "            If a single string is provided, it will be treated as a single variable. Default is None.\n",
    "            This list should not contain target feature.\n",
    "        target (str): Name of the target feature which is not going to be transformed.\n",
    "\n",
    "    Attributes:\n",
    "        features (list): List of column names (features) to perform StandardScaler.\n",
    "        target (str): Name of the target feature which is not going to be transformed.\n",
    "\n",
    "    Methods:\n",
    "        fit(X, y=None):\n",
    "            This method does not perform any actual training or fitting.\n",
    "            It returns the transformer instance itself.\n",
    "\n",
    "        transform(X):\n",
    "            Transforms features using StandardScaler, except on target feature.\n",
    "            Returns the modified DataFrame.\n",
    "\n",
    "    Example usage:\n",
    "    ```\n",
    "    from sklearn.pipeline import Pipeline\n",
    "\n",
    "    # Instantiate the custom transformer\n",
    "    standardscaler = Standard_Scaler(features=['category1', 'category2'], target='class')\n",
    "\n",
    "    # Define the pipeline with the custom transformer\n",
    "    pipeline = Pipeline([\n",
    "        ('standardscaler', standardscaler),\n",
    "        # Other pipeline steps...\n",
    "    ])\n",
    "\n",
    "    # Fit and transform the data using the pipeline\n",
    "    X_transformed = pipeline.fit_transform(X)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    def __init__(self, features=None, target=None):\n",
    "        \"\"\"\n",
    "        Initialize the Standard_Scaler transformer.\n",
    "\n",
    "        Parameters:\n",
    "            features (list or str): List of column names (features) to perform StandardScaler.\n",
    "                If a single string is provided, it will be treated as a single variable. Default is None.\n",
    "                This list should not contain target feature.\n",
    "            target (str): Name of the target feature which is not going to be transformed.\n",
    "        \"\"\"\n",
    "        self.features = [features] if not isinstance(features, list) else features\n",
    "        self.target = target\n",
    "\n",
    "    def fit(self, X):\n",
    "        \"\"\"\n",
    "        This method does not perform any actual training or fitting.\n",
    "        It returns the transformer instance itself.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input data to be transformed.\n",
    "\n",
    "        Returns:\n",
    "            self (Standard_Scaler): The transformer instance.\n",
    "        \"\"\"\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        \"\"\"\n",
    "        Performs Standard_Scaler for the specified features and returns the modified DataFrame.\n",
    "\n",
    "        Parameters:\n",
    "            X (pd.DataFrame): Input data to be transformed.\n",
    "\n",
    "        Returns:\n",
    "            X_transformed (pd.DataFrame): Transformed DataFrame.\n",
    "        \"\"\"\n",
    "\n",
    "        self.standard_scaler = StandardScaler()\n",
    "        X = X.copy()\n",
    "        X_features_transformed = pd.DataFrame(self.standard_scaler.fit_transform(X[self.features]))\n",
    "        X_features_transformed.columns = self.features\n",
    "        X = pd.concat([X_features_transformed, X[self.target]], axis=1)\n",
    "\n",
    "        return X\n",
    "    \n",
    "    \n",
    "#print(CATEGORICAL_FEATURES)\n",
    "#aux = raw_df.copy()\n",
    "#aux['CHAS'] = aux['CHAS'].astype(str)\n",
    "#aux['RAD'] = aux['RAD'].astype(str)\n",
    "#one_encoder = OneHotEncoder(features=['RAD'])\n",
    "#one_encoder.fit(aux)\n",
    "#AUX = one_encoder.transform(aux)\n",
    "#AUX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transformations to normalize features\n",
    "#https://towardsdatascience.com/types-of-transformations-for-better-normal-distribution-61c22668d3b9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline\n",
    "\n",
    "The code below is a scikit-learn pipeline called housepricing_pipeline, that is used for data preprocessing and modeling for a Hose-price dataset regression task. Each step in the pipeline corresponds to a specific data transformation or modeling step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_pipeline = Pipeline(\n",
    "    [   ('missing_indicator', MissingIndicator(variables=FEATURES)),\n",
    "        ('iqr_dropoutliers', IQR_DropOutliers(features=FEATURES, n=1)),\n",
    "        ('drop_missing', DropMissing()),\n",
    "        #('oh_encoder', OneHotEncoder(features=CATEGORICAL_FEATURES))\n",
    "        ('scaler', Standard_Scaler(features=FEATURES, target=TARGET))\n",
    "        #('scaler', StandardScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;missing_indicator&#x27;,\n",
       "                 MissingIndicator(variables=[&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;,\n",
       "                                             &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;, &#x27;DIS&#x27;, &#x27;RAD&#x27;,\n",
       "                                             &#x27;TAX&#x27;, &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;])),\n",
       "                (&#x27;iqr_dropoutliers&#x27;,\n",
       "                 IQR_DropOutliers(features=[&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;,\n",
       "                                            &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;, &#x27;DIS&#x27;, &#x27;RAD&#x27;,\n",
       "                                            &#x27;TAX&#x27;, &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;],\n",
       "                                  n=1)),\n",
       "                (&#x27;drop_missing&#x27;, DropMissing()),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 Standard_Scaler(features=[&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;, &#x27;NOX&#x27;,\n",
       "                                           &#x27;RM&#x27;, &#x27;AGE&#x27;, &#x27;DIS&#x27;, &#x27;RAD&#x27;, &#x27;TAX&#x27;,\n",
       "                                           &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;],\n",
       "                                 target=&#x27;MEDV&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;missing_indicator&#x27;,\n",
       "                 MissingIndicator(variables=[&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;,\n",
       "                                             &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;, &#x27;DIS&#x27;, &#x27;RAD&#x27;,\n",
       "                                             &#x27;TAX&#x27;, &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;])),\n",
       "                (&#x27;iqr_dropoutliers&#x27;,\n",
       "                 IQR_DropOutliers(features=[&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;,\n",
       "                                            &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;, &#x27;DIS&#x27;, &#x27;RAD&#x27;,\n",
       "                                            &#x27;TAX&#x27;, &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;],\n",
       "                                  n=1)),\n",
       "                (&#x27;drop_missing&#x27;, DropMissing()),\n",
       "                (&#x27;scaler&#x27;,\n",
       "                 Standard_Scaler(features=[&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;, &#x27;NOX&#x27;,\n",
       "                                           &#x27;RM&#x27;, &#x27;AGE&#x27;, &#x27;DIS&#x27;, &#x27;RAD&#x27;, &#x27;TAX&#x27;,\n",
       "                                           &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;],\n",
       "                                 target=&#x27;MEDV&#x27;))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MissingIndicator</label><div class=\"sk-toggleable__content\"><pre>MissingIndicator(variables=[&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;, &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;,\n",
       "                            &#x27;DIS&#x27;, &#x27;RAD&#x27;, &#x27;TAX&#x27;, &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;])</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">IQR_DropOutliers</label><div class=\"sk-toggleable__content\"><pre>IQR_DropOutliers(features=[&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;, &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;,\n",
       "                           &#x27;DIS&#x27;, &#x27;RAD&#x27;, &#x27;TAX&#x27;, &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;],\n",
       "                 n=1)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DropMissing</label><div class=\"sk-toggleable__content\"><pre>DropMissing()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Standard_Scaler</label><div class=\"sk-toggleable__content\"><pre>Standard_Scaler(features=[&#x27;CRIM&#x27;, &#x27;ZN&#x27;, &#x27;INDUS&#x27;, &#x27;CHAS&#x27;, &#x27;NOX&#x27;, &#x27;RM&#x27;, &#x27;AGE&#x27;,\n",
       "                          &#x27;DIS&#x27;, &#x27;RAD&#x27;, &#x27;TAX&#x27;, &#x27;PTRATIO&#x27;, &#x27;B&#x27;, &#x27;LSTAT&#x27;],\n",
       "                target=&#x27;MEDV&#x27;)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('missing_indicator',\n",
       "                 MissingIndicator(variables=['CRIM', 'ZN', 'INDUS', 'CHAS',\n",
       "                                             'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "                                             'TAX', 'PTRATIO', 'B', 'LSTAT'])),\n",
       "                ('iqr_dropoutliers',\n",
       "                 IQR_DropOutliers(features=['CRIM', 'ZN', 'INDUS', 'CHAS',\n",
       "                                            'NOX', 'RM', 'AGE', 'DIS', 'RAD',\n",
       "                                            'TAX', 'PTRATIO', 'B', 'LSTAT'],\n",
       "                                  n=1)),\n",
       "                ('drop_missing', DropMissing()),\n",
       "                ('scaler',\n",
       "                 Standard_Scaler(features=['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX',\n",
       "                                           'RM', 'AGE', 'DIS', 'RAD', 'TAX',\n",
       "                                           'PTRATIO', 'B', 'LSTAT'],\n",
       "                                 target='MEDV'))])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the-boston-houseprice-data.zip to .\\the-boston-houseprice-data\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12.3k/12.3k [00:00<00:00, 408kB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset downloaded: the-boston-houseprice-data\\boston.csv\n",
      "And stored in: ./datasets/data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Load dataset\n",
    "retrieve_data()\n",
    "raw_df = pd.read_csv(DATASETS_DIR + DATA_RETRIEVED, delimiter = \",\")\n",
    "\n",
    "#Use this two lines below if OHE is used\n",
    "#raw_df['CHAS'] = raw_df['CHAS'].astype(str)\n",
    "#raw_df['RAD'] = raw_df['RAD'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.365156</td>\n",
       "      <td>0.366831</td>\n",
       "      <td>-1.260880</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.078075</td>\n",
       "      <td>0.480856</td>\n",
       "      <td>-0.080474</td>\n",
       "      <td>0.113035</td>\n",
       "      <td>-0.941937</td>\n",
       "      <td>-0.600628</td>\n",
       "      <td>-1.540026</td>\n",
       "      <td>0.382988</td>\n",
       "      <td>-1.120097</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.362040</td>\n",
       "      <td>-0.477556</td>\n",
       "      <td>-0.553790</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.699104</td>\n",
       "      <td>0.229787</td>\n",
       "      <td>0.409621</td>\n",
       "      <td>0.560174</td>\n",
       "      <td>-0.819004</td>\n",
       "      <td>-0.937690</td>\n",
       "      <td>-0.324994</td>\n",
       "      <td>0.382988</td>\n",
       "      <td>-0.468747</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.362043</td>\n",
       "      <td>-0.477556</td>\n",
       "      <td>-0.553790</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.699104</td>\n",
       "      <td>1.475351</td>\n",
       "      <td>-0.227145</td>\n",
       "      <td>0.560174</td>\n",
       "      <td>-0.819004</td>\n",
       "      <td>-0.937690</td>\n",
       "      <td>-0.324994</td>\n",
       "      <td>0.319181</td>\n",
       "      <td>-1.268843</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.361288</td>\n",
       "      <td>-0.477556</td>\n",
       "      <td>-1.280191</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.798108</td>\n",
       "      <td>1.170482</td>\n",
       "      <td>-0.774478</td>\n",
       "      <td>1.118449</td>\n",
       "      <td>-0.696070</td>\n",
       "      <td>-1.062528</td>\n",
       "      <td>0.112418</td>\n",
       "      <td>0.347400</td>\n",
       "      <td>-1.439509</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.355842</td>\n",
       "      <td>-0.477556</td>\n",
       "      <td>-1.280191</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>-0.798108</td>\n",
       "      <td>1.413399</td>\n",
       "      <td>-0.473981</td>\n",
       "      <td>1.118449</td>\n",
       "      <td>-0.696070</td>\n",
       "      <td>-1.062528</td>\n",
       "      <td>0.112418</td>\n",
       "      <td>0.382988</td>\n",
       "      <td>-1.065296</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>-0.356796</td>\n",
       "      <td>-0.477556</td>\n",
       "      <td>0.168154</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.236940</td>\n",
       "      <td>0.510202</td>\n",
       "      <td>0.059042</td>\n",
       "      <td>-0.708447</td>\n",
       "      <td>-0.941937</td>\n",
       "      <td>-0.744192</td>\n",
       "      <td>1.230248</td>\n",
       "      <td>0.306011</td>\n",
       "      <td>-0.385762</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>-0.359373</td>\n",
       "      <td>-0.477556</td>\n",
       "      <td>0.168154</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.236940</td>\n",
       "      <td>-0.260939</td>\n",
       "      <td>0.330920</td>\n",
       "      <td>-0.805868</td>\n",
       "      <td>-0.941937</td>\n",
       "      <td>-0.744192</td>\n",
       "      <td>1.230248</td>\n",
       "      <td>0.382988</td>\n",
       "      <td>-0.478141</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>-0.357073</td>\n",
       "      <td>-0.477556</td>\n",
       "      <td>0.168154</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.236940</td>\n",
       "      <td>1.134614</td>\n",
       "      <td>0.842479</td>\n",
       "      <td>-0.867043</td>\n",
       "      <td>-0.941937</td>\n",
       "      <td>-0.744192</td>\n",
       "      <td>1.230248</td>\n",
       "      <td>0.382988</td>\n",
       "      <td>-1.016758</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>-0.349823</td>\n",
       "      <td>-0.477556</td>\n",
       "      <td>0.168154</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.236940</td>\n",
       "      <td>0.837896</td>\n",
       "      <td>0.781665</td>\n",
       "      <td>-0.754175</td>\n",
       "      <td>-0.941937</td>\n",
       "      <td>-0.744192</td>\n",
       "      <td>1.230248</td>\n",
       "      <td>0.328901</td>\n",
       "      <td>-0.885235</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>-0.359055</td>\n",
       "      <td>-0.477556</td>\n",
       "      <td>0.168154</td>\n",
       "      <td>-0.239046</td>\n",
       "      <td>0.236940</td>\n",
       "      <td>-0.407668</td>\n",
       "      <td>0.477591</td>\n",
       "      <td>-0.694988</td>\n",
       "      <td>-0.941937</td>\n",
       "      <td>-0.744192</td>\n",
       "      <td>1.230248</td>\n",
       "      <td>0.382988</td>\n",
       "      <td>-0.666031</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>444 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
       "0   -0.365156  0.366831 -1.260880 -0.239046 -0.078075  0.480856 -0.080474   \n",
       "1   -0.362040 -0.477556 -0.553790 -0.239046 -0.699104  0.229787  0.409621   \n",
       "2   -0.362043 -0.477556 -0.553790 -0.239046 -0.699104  1.475351 -0.227145   \n",
       "3   -0.361288 -0.477556 -1.280191 -0.239046 -0.798108  1.170482 -0.774478   \n",
       "4   -0.355842 -0.477556 -1.280191 -0.239046 -0.798108  1.413399 -0.473981   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "439 -0.356796 -0.477556  0.168154 -0.239046  0.236940  0.510202  0.059042   \n",
       "440 -0.359373 -0.477556  0.168154 -0.239046  0.236940 -0.260939  0.330920   \n",
       "441 -0.357073 -0.477556  0.168154 -0.239046  0.236940  1.134614  0.842479   \n",
       "442 -0.349823 -0.477556  0.168154 -0.239046  0.236940  0.837896  0.781665   \n",
       "443 -0.359055 -0.477556  0.168154 -0.239046  0.236940 -0.407668  0.477591   \n",
       "\n",
       "          DIS       RAD       TAX   PTRATIO         B     LSTAT  MEDV  \n",
       "0    0.113035 -0.941937 -0.600628 -1.540026  0.382988 -1.120097  24.0  \n",
       "1    0.560174 -0.819004 -0.937690 -0.324994  0.382988 -0.468747  21.6  \n",
       "2    0.560174 -0.819004 -0.937690 -0.324994  0.319181 -1.268843  34.7  \n",
       "3    1.118449 -0.696070 -1.062528  0.112418  0.347400 -1.439509  33.4  \n",
       "4    1.118449 -0.696070 -1.062528  0.112418  0.382988 -1.065296  36.2  \n",
       "..        ...       ...       ...       ...       ...       ...   ...  \n",
       "439 -0.708447 -0.941937 -0.744192  1.230248  0.306011 -0.385762  22.4  \n",
       "440 -0.805868 -0.941937 -0.744192  1.230248  0.382988 -0.478141  20.6  \n",
       "441 -0.867043 -0.941937 -0.744192  1.230248  0.382988 -1.016758  23.9  \n",
       "442 -0.754175 -0.941937 -0.744192  1.230248  0.328901 -0.885235  22.0  \n",
       "443 -0.694988 -0.941937 -0.744192  1.230248  0.382988 -0.666031  11.9  \n",
       "\n",
       "[444 rows x 14 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_transformed = pd.DataFrame(transform_pipeline.fit_transform(raw_df))\n",
    "#df_transformed.columns = COLUMNS\n",
    "df_transformed = transform_pipeline.fit_transform(raw_df)\n",
    "df_transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_transformed.drop(TARGET, axis=1), df_transformed[TARGET], test_size=0.2, random_state=SEED_SPLIT)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(raw_df.drop(TARGET, axis=1), raw_df[TARGET], test_size=0.2, random_state=SEED_SPLIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and training model\n",
    "RF_model = RandomForestRegressor(n_estimators = 100, random_state = SEED_MODEL)\n",
    "RF_model.fit(X_train, y_train)\n",
    "#RF_model.fit(X_transformed, y_transformed)\n",
    "\n",
    "# Model making a prediction on test data\n",
    "y_pred = RF_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>R2 Score</th>\n",
       "      <th>Adjusted R2 Score</th>\n",
       "      <th>Cross Validated R2 Score</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.863164</td>\n",
       "      <td>0.839446</td>\n",
       "      <td>0.859688</td>\n",
       "      <td>2.784993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  R2 Score  Adjusted R2 Score  Cross Validated R2 Score  \\\n",
       "0  Random Forest  0.863164           0.839446                  0.859688   \n",
       "\n",
       "       RMSE  \n",
       "0  2.784993  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndf = Reg_Models_Evaluation_Metrics(RF_model, X_train, y_train, X_test, y_test, y_pred)\n",
    "\n",
    "rf_score = pd.DataFrame(data = ndf, columns=['R2 Score','Adjusted R2 Score','Cross Validated R2 Score','RMSE'])\n",
    "rf_score.insert(0, 'Model', 'Random Forest')\n",
    "rf_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persisting the trained model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model stored in: trained_models/random_forest_output.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the model using joblib\n",
    "persist_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.752])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_pred = pd.DataFrame([[0.06905,0.0,2.18,0,0.458,7.147,54.2,6.0622,3,222.0,18.7,396.90,5.33]], columns = FEATURES)\n",
    "new_data_pred = new_data_pred[SELECTED_FEATURES].copy()\n",
    "RF_model.predict(new_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24.678])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data_pred = pd.DataFrame([[0.02729,0.0\t,7.07,0\t,0.469,7.185,61.1,4.9671,2,242.0,17.8,392.83,4.03]], columns = FEATURES)\n",
    "new_data_pred = new_data_pred[SELECTED_FEATURES].copy()\n",
    "RF_model.predict(new_data_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34.422 17.066 19.844 23.912 28.818 27.686 22.075 31.446 13.86  17.338]\n",
      "286    33.4\n",
      "22     15.2\n",
      "46     20.0\n",
      "93     25.0\n",
      "441    23.9\n",
      "101    26.5\n",
      "90     22.6\n",
      "57     31.6\n",
      "148    17.8\n",
      "24     15.6\n",
      "Name: MEDV, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "new_data = X_test.tail(10)\n",
    "new_data = new_data[SELECTED_FEATURES].copy()\n",
    "print(RF_model.predict(new_data))\n",
    "print(y_test.tail(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
